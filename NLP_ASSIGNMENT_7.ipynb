{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Exercise 1.\n",
        "Sentiment Analysis\n",
        "\n",
        "• Using textblob, what is the probability that the sentiment in the\n",
        "Burbank text is going to negative?\n",
        "\n",
        "Exercise 2.\n",
        "Sentiment Analysis\n",
        "\n",
        "• Using the data from exercise 1 and textblob, what is the overall\n",
        "sentiment and subjectivity?\n",
        "\n",
        "Exercise 3.\n",
        "\n",
        " Key topic using ‘Word’ from textblob (very simple way to\n",
        "determine the key topics) based on the Burbank text file.\n",
        "\n",
        "• Import Word from textblob. Identify the key topics by using Word\n",
        "from textblob.\n",
        "\n",
        "Exercise 4.\n",
        "\n",
        "Sentiment analysis with spaCy.\n",
        "\n",
        "• Load the datasets ‘amazon_cells_labelled.txt’, ‘imdb_labelled.txt’,\n",
        "‘yelp_labelled.txt’\n",
        "\n",
        "• Create ‘combined_col’ by joining the tables such that\n",
        "combined_col=[data_amazon, data_imdb, data_yelp]\n",
        "\n",
        "• Check the structure of data_amazon\n",
        "\n",
        "• Add headers for columns in each dataset: ‘Review’ and ‘Label’\n",
        "\n",
        "• Create a “Company’ column to identify each company ‘Amazon’,\n",
        "‘imdb’, and ‘yelp’\n",
        "\n",
        "• Explore the structure of the new dataset called ‘comb_data’\n",
        "\n",
        "• Use ‘comb_data.to_csv’ to create the ‘Sentiment_Analysis_Dataset’\n",
        "\n",
        "• Print the columns\n",
        "\n",
        "• Check for null values\n",
        "\n",
        "• Import STOP_WORDS from spacy and stopwords from\n",
        "spacy.lang.en.stop_words\n",
        "\n",
        "• Build a list of stopwords for filtering\n",
        "\n",
        "• Import string, define ‘punctuations’ and define a ‘parser’\n",
        "\n",
        "• Tokenize the sentences\n",
        "\n",
        "• Import ‘CountVectorize’, ‘TfidVectorizer’, ‘accuracy_score’,\n",
        "‘TransformerMixin’, ‘Pipeline’, and ‘LinearSVC’\n",
        "\n",
        "• Create a class 'predictors(TransformerMixin)'. Within the class, define 'transform', 'fit', and 'get_params'\n",
        "\n",
        "• Create a basic function to clean the text\n",
        "\n",
        "• Vectorize and use LinearSVC as a classifier\n",
        "\n",
        "• Use TfidfVectorizer\n",
        "\n",
        "• Split the ‘com_data’ dataset into a train and test (20%) set\n",
        "\n",
        "• Create a pipeline to clean, tokenize, vectorize, and classify as\n",
        "‘pipe_countvect’\n",
        "\n",
        "• Fit the data\n",
        "\n",
        "• Predict with the test dataset\n",
        "\n",
        "• Prediction results as ‘1’ for positive reviews, and ‘0’ for negative\n",
        "reviews\n",
        "\n",
        "• Use print(sample, “Prediction➔”, pred)\n",
        "\n",
        "• Determine the accuracy for the test dataset, X_test/sample\n",
        "prediction, and train dataset"
      ],
      "metadata": {
        "id": "Ug2P-WWOnL-G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Excersice 1"
      ],
      "metadata": {
        "id": "CXAP6lWiYype"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "394HapOKnIbQ",
        "outputId": "ba438d63-ec49-4d3e-9a20-a398a68d7aa8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probability of negative sentiment: 0\n"
          ]
        }
      ],
      "source": [
        "import textblob\n",
        "from textblob import TextBlob\n",
        "\n",
        "with open('Burbank.txt', 'r') as f:\n",
        "    text = f.read()\n",
        "\n",
        "blob = TextBlob(text)\n",
        "sentiment = blob.sentiment\n",
        "\n",
        "if sentiment[0] < 0:\n",
        "    print(\"Probability of negative sentiment:\", abs(sentiment[0]))\n",
        "else:\n",
        "    print(\"Probability of negative sentiment: 0\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing teh sentiment and Subjectivity of the text\n",
        "print(\"Overall sentiment:\", sentiment[0])\n",
        "print(\"Subjectivity:\", sentiment[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-HDM_5iodDN",
        "outputId": "cd269efd-0695-44d1-da55-5bd061719503"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall sentiment: 0.09869334480780263\n",
            "Subjectivity: 0.3790877796901893\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Excersice 2"
      ],
      "metadata": {
        "id": "R3VGMuB_upy7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmjzk5-9uqQk",
        "outputId": "ac5e07d8-1d38-4b1f-a952-52bcbb6490c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5d9ZUEYluvkZ",
        "outputId": "38f059ba-74a7-43eb-d842-57d500a6b6bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "with open('Burbank.txt', 'r') as f:\n",
        "    text = f.read()\n",
        "\n",
        "blob = TextBlob(text)\n",
        "words = blob.words\n"
      ],
      "metadata": {
        "id": "cF5VwbOsorvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing FreqDist\n",
        "from nltk.probability import FreqDist\n"
      ],
      "metadata": {
        "id": "hCVWx_SgouBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating fdist for most commonly repeted words\n",
        "fdist = FreqDist(words)\n",
        "frequent_words = fdist.most_common(5)"
      ],
      "metadata": {
        "id": "hVIjdFJPvWop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing the Top 5 key topics\n",
        "print(\"Top 5 Key Topics:\")\n",
        "for word, freq in frequent_words:\n",
        "    print(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtdGjFCPvnhk",
        "outputId": "6d5021bf-32bc-420c-d874-2575b9c5165e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 Key Topics:\n",
            "the\n",
            "of\n",
            "to\n",
            "and\n",
            "that\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Excersice 3"
      ],
      "metadata": {
        "id": "YXqPI_b-xF_w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the Required Libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.base import TransformerMixin"
      ],
      "metadata": {
        "id": "1QpW5M7tvqAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the  datasets\n",
        "amazon = pd.read_csv('amazon_cells_labelled.txt', sep='\\t', header=None)\n",
        "imdb = pd.read_csv('imdb_labelled.txt', sep='\\t', header=None)\n",
        "yelp = pd.read_csv('yelp_labelled.txt', sep='\\t', header=None)\n"
      ],
      "metadata": {
        "id": "PtqMX_o2xLF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combining datasets\n",
        "combined_col = pd.concat([amazon, imdb, yelp], ignore_index=True)\n"
      ],
      "metadata": {
        "id": "onK1vQpXxOb1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding column headers\n",
        "combined_col.columns = ['Review', 'Label']\n"
      ],
      "metadata": {
        "id": "W7eMfAknxzte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding a new column called  company\n",
        "combined_col['Company'] = ''\n",
        "combined_col.loc[combined_col.index < amazon.shape[0], 'Company'] = 'Amazon'\n",
        "combined_col.loc[(combined_col.index >= amazon.shape[0]) & (combined_col.index < (amazon.shape[0] + imdb.shape[0])), 'Company'] = 'IMDB'\n",
        "combined_col.loc[combined_col.index >= (amazon.shape[0] + imdb.shape[0]), 'Company'] = 'Yelp'\n",
        "\n",
        "comb_data = combined_col\n",
        "comb_data.to_csv('Sentiment_Analysis_Dataset.csv', index=False)"
      ],
      "metadata": {
        "id": "RuW0nAw9x3NC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exploring the  data\n",
        "print(comb_data.columns)\n",
        "print(comb_data.isnull().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAXXo7Xyx7Ek",
        "outputId": "9e13ac11-de51-4cb4-f019-6a9305071c84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Review', 'Label', 'Company'], dtype='object')\n",
            "Review     0\n",
            "Label      0\n",
            "Company    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Impoting the  stopwords\n",
        "import spacy\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "stopwords = list(STOP_WORDS)\n"
      ],
      "metadata": {
        "id": "tzbkVavNyDRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the  stopwords list\n",
        "import string\n",
        "punctuations = string.punctuation\n",
        "parser = spacy.lang.en.English()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsG0RJ44yHUn",
        "outputId": "0a41714a-6571-4dea-80e4-bc02a64993b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<spacy.lang.en.English at 0x7dc18ee2b550>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizing the Reveiw\n",
        "nltk_tokens =combined_col['Review'].apply(lambda x: parser(x))\n"
      ],
      "metadata": {
        "id": "1foBJMq1yQ95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizers and model\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import LinearSVC"
      ],
      "metadata": {
        "id": "Qw-qJm5_yXO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom transformer\n",
        "class predictors(TransformerMixin):\n",
        "\n",
        "    def transform(self, X, **transform_params):\n",
        "        return [clean_text(text) for text in X]\n",
        "\n",
        "    def fit(self, X, y=None, **fit_params):\n",
        "        return self\n",
        "\n",
        "    def get_params(self, deep=True):\n",
        "        return {}\n"
      ],
      "metadata": {
        "id": "D5dEV0ydyZoH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean text function\n",
        "def clean_text(text):\n",
        "    return text.strip().lower()"
      ],
      "metadata": {
        "id": "ER0wcrhtycNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create pipeline\n",
        "pipe_countvect = Pipeline([(\"cleaner\", predictors()),\n",
        "                   ('vectorizer', CountVectorizer()),\n",
        "                   ('classifier', LinearSVC())])"
      ],
      "metadata": {
        "id": "AboXa2HtygcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(comb_data['Review'], comb_data['Label'], test_size=0.2)\n"
      ],
      "metadata": {
        "id": "7pnfpPLcyibh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit pipeline\n",
        "pipe_countvect.fit(X_train,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "N1bmHCztyleI",
        "outputId": "444842a0-1a42-4cf5-ee7c-3496ef1340eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('cleaner', <__main__.predictors object at 0x7dc18e7d2c20>),\n",
              "                ('vectorizer', CountVectorizer()),\n",
              "                ('classifier', LinearSVC())])"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;cleaner&#x27;, &lt;__main__.predictors object at 0x7dc18e7d2c20&gt;),\n",
              "                (&#x27;vectorizer&#x27;, CountVectorizer()),\n",
              "                (&#x27;classifier&#x27;, LinearSVC())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;cleaner&#x27;, &lt;__main__.predictors object at 0x7dc18e7d2c20&gt;),\n",
              "                (&#x27;vectorizer&#x27;, CountVectorizer()),\n",
              "                (&#x27;classifier&#x27;, LinearSVC())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">predictors</label><div class=\"sk-toggleable__content\"><pre>&lt;__main__.predictors object at 0x7dc18e7d2c20&gt;</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC()</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict\n",
        "pred = pipe_countvect.predict(X_test)\n"
      ],
      "metadata": {
        "id": "Gq6gIvziynv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print results\n",
        "for sample, pred in list(zip(X_test, pred))[:3]:\n",
        "    print(sample, \"Prediction -->\", pred)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OWdKxigyq_B",
        "outputId": "2e799202-c32d-4af8-db8e-6d7b265dbaf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "However, my recent experience at this particular location was not so good. Prediction --> 0\n",
            "WORTHWHILE. Prediction --> 1\n",
            "Phone falls out easily. Prediction --> 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Accuracy\n",
        "print(\"Test accuracy:\", accuracy_score(y_test, pred_class))\n",
        "print(\"Train accuracy:\", pipe_countvect.score(X_train, y_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icQd4_8Vyxvf",
        "outputId": "adbfd69c-eb02-40cd-8355-4c1fe52ff01f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.8236363636363636\n",
            "Train accuracy: 0.9986351228389445\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PY-bX3sAza9X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}